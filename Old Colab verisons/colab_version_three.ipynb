{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook_after_big_index.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "udVmmcNf0c1X",
        "xPZqaHvRBJyR",
        "ilQgM7m3BPgs",
        "aTO0Fd5I-OpC",
        "VEM0wf9mAdTN",
        "_H4UmiLSAGA8",
        "rGliVCa-AVt8",
        "-_yrc27ACNwL",
        "0H9HtYRnD1l5",
        "opkGx9riBykd",
        "bd__I0S85M5p"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "udVmmcNf0c1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from collections import Counter, OrderedDict\n",
        "import itertools\n",
        "from itertools import islice, count, groupby\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from operator import itemgetter\n",
        "import nltk\n",
        "from nltk.stem.porter import *\n",
        "from nltk.corpus import stopwords\n",
        "from time import time\n",
        "from timeit import timeit\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.cloud import storage\n",
        "import math\n",
        "nltk.download('stopwords')\n",
        "import builtins\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%load_ext google.colab.data_table\n",
        "import bz2\n",
        "from functools import partial\n",
        "from collections import Counter, OrderedDict\n",
        "import pickle\n",
        "import heapq\n",
        "from itertools import islice, count, groupby\n",
        "from xml.etree import ElementTree\n",
        "import codecs\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "from operator import itemgetter\n",
        "import nltk\n",
        "from nltk.stem.porter import *\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "from time import time\n",
        "import hashlib\n",
        "def _hash(s):\n",
        "    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zmg92hymzjtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713734a2-6200-4a50-bad2-9ae508f8507f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#helper functions"
      ],
      "metadata": {
        "id": "xPZqaHvRBJyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_lst(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ],
      "metadata": {
        "id": "mDNKiHcDGn5w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unq(list1):\n",
        " \n",
        "    # initialize a null list\n",
        "    unique_list = []\n",
        "     \n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    return unique_list"
      ],
      "metadata": {
        "id": "pOhTHMbjFMhb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#getting json query data"
      ],
      "metadata": {
        "id": "ilQgM7m3BPgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "with open('queries_train.json', 'rt') as f:\n",
        "  queries_to_docs_raw = json.load(f)\n",
        "\n",
        "doc_lst=flatten_lst([docs for q,docs in queries_to_docs_raw.items()])\n"
      ],
      "metadata": {
        "id": "b4AgDWF4TwXa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**index from assignment 2**"
      ],
      "metadata": {
        "id": "CJlA9PHUI8Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from collections import Counter, OrderedDict, defaultdict\n",
        "import itertools\n",
        "from itertools import islice, count, groupby\n",
        "import os\n",
        "import re\n",
        "from operator import itemgetter\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from contextlib import closing\n",
        "\n",
        "BLOCK_SIZE = 1999998\n",
        "\n",
        "class MultiFileWriter:\n",
        "    \"\"\" Sequential binary writer to multiple files of up to BLOCK_SIZE each. \"\"\"\n",
        "    def __init__(self, base_dir, name):\n",
        "        self._base_dir = Path(base_dir)\n",
        "        self._name = name\n",
        "        self._file_gen = (open(self._base_dir / f'{name}_{i:03}.bin', 'wb') \n",
        "                          for i in itertools.count())\n",
        "        self._f = next(self._file_gen)\n",
        "    \n",
        "    def write(self, b):\n",
        "      locs = []\n",
        "      while len(b) > 0:\n",
        "        pos = self._f.tell()\n",
        "        remaining = BLOCK_SIZE - pos\n",
        "        # if the current file is full, close and open a new one.\n",
        "        if remaining == 0:  \n",
        "          self._f.close()\n",
        "          self._f = next(self._file_gen)\n",
        "          pos, remaining = 0, BLOCK_SIZE\n",
        "        self._f.write(b[:remaining])\n",
        "        locs.append((self._f.name, pos))\n",
        "        b = b[remaining:]\n",
        "      return locs\n",
        "\n",
        "    def close(self):\n",
        "      self._f.close()\n",
        "\n",
        "class MultiFileReader:\n",
        "  \"\"\" Sequential binary reader of multiple files of up to BLOCK_SIZE each. \"\"\"\n",
        "  def __init__(self):\n",
        "    self._open_files = {}\n",
        "\n",
        "  def read(self, locs, n_bytes):\n",
        "    b = []\n",
        "    for f_name, offset in locs:\n",
        "      if f_name not in self._open_files:\n",
        "        self._open_files[f_name] = open(f_name, 'rb')\n",
        "      f = self._open_files[f_name]\n",
        "      f.seek(offset)\n",
        "      n_read = builtins.min(n_bytes, BLOCK_SIZE - offset)\n",
        "      b.append(f.read(n_read))\n",
        "      n_bytes -= n_read\n",
        "    return b''.join(b)\n",
        "  \n",
        "  def close(self):\n",
        "    for f in self._open_files.values():\n",
        "      f.close()\n",
        "\n",
        "  def __exit__(self, exc_type, exc_value, traceback):\n",
        "    self.close()\n",
        "    return False\n",
        "\n",
        "TUPLE_SIZE = 6       # We're going to pack the doc_id and tf values in this \n",
        "                     # many bytes.\n",
        "TF_MASK = 2 ** 16 - 1 # Masking the 16 low bits of an integer\n",
        "\n",
        "class InvertedIndex:  \n",
        "  def __init__(self, docs={}):\n",
        "    \"\"\" Initializes the inverted index and add documents to it (if provided).\n",
        "    Parameters:\n",
        "    -----------\n",
        "      docs: dict mapping doc_id to list of tokens\n",
        "    \"\"\"\n",
        "    # stores document frequency per term\n",
        "    self.df = Counter()\n",
        "    # length of each doc\n",
        "    self.DL=Counter()\n",
        "    # stores posting list per term while building the index (internally), \n",
        "    # otherwise too big to store in memory.\n",
        "    self._posting_list = defaultdict(list)\n",
        "    # mapping a term to posting file locations, which is a list of \n",
        "    # (file_name, offset) pairs. Since posting lists are big we are going to\n",
        "    # write them to disk and just save their location in this list. We are \n",
        "    # using the MultiFileWriter helper class to write fixed-size files and store\n",
        "    # for each term/posting list its list of locations. The offset represents \n",
        "    # the number of bytes from the beginning of the file where the posting list\n",
        "    # starts. \n",
        "    self.posting_locs = defaultdict(list)\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    for doc_id, tokens in docs.items():\n",
        "      self.add_doc(doc_id, tokens)\n",
        "\n",
        "  def add_doc(self, doc_id, tokens):\n",
        "    \"\"\" Adds a document to the index with a given `doc_id` and tokens. It counts\n",
        "        the tf of tokens, then update the index (in memory, no storage \n",
        "        side-effects).\n",
        "    \"\"\"\n",
        "    w2cnt = Counter(tokens)\n",
        "    self.term_total.update(w2cnt)\n",
        "    for w, cnt in w2cnt.items():\n",
        "      self.df[w] = self.df.get(w, 0) + 1\n",
        "      self._posting_list[w].append((doc_id, cnt))\n",
        "\n",
        "  def write_index(self, base_dir, name):\n",
        "    \"\"\" Write the in-memory index to disk. Results in the file: \n",
        "        (1) `name`.pkl containing the global term stats (e.g. df).\n",
        "    \"\"\"\n",
        "    self._write_globals(base_dir, name)\n",
        "\n",
        "  def _write_globals(self, base_dir, name):\n",
        "    with open(Path(base_dir) / f'{name}.pkl', 'wb') as f:\n",
        "      pickle.dump(self, f)\n",
        "\n",
        "  def __getstate__(self):\n",
        "    \"\"\" Modify how the object is pickled by removing the internal posting lists\n",
        "        from the object's state dictionary. \n",
        "    \"\"\"\n",
        "    state = self.__dict__.copy()\n",
        "    del state['_posting_list']\n",
        "    return state\n",
        "\n",
        "  def posting_lists_iter(self):\n",
        "    \"\"\" A generator that reads one posting list from disk and yields \n",
        "        a (word:str, [(doc_id:int, tf:int), ...]) tuple.\n",
        "    \"\"\"\n",
        "    with closing(MultiFileReader()) as reader:\n",
        "      for w, locs in self.posting_locs.items():\n",
        "        b = reader.read(locs, self.df[w] * TUPLE_SIZE)\n",
        "        posting_list = []\n",
        "        for i in range(self.df[w]):\n",
        "          doc_id = int.from_bytes(b[i*TUPLE_SIZE:i*TUPLE_SIZE+4], 'big')\n",
        "          tf = int.from_bytes(b[i*TUPLE_SIZE+4:(i+1)*TUPLE_SIZE], 'big')\n",
        "          posting_list.append((doc_id, tf))\n",
        "        yield w, posting_list\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def read_index(base_dir, name):\n",
        "    with open(Path(base_dir) / f'{name}.pkl', 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "\n",
        "  @staticmethod\n",
        "  def delete_index(base_dir, name):\n",
        "    path_globals = Path(base_dir) / f'{name}.pkl'\n",
        "    path_globals.unlink()\n",
        "    for p in Path(base_dir).rglob(f'{name}_*.bin'):\n",
        "      p.unlink()\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def write_a_posting_list(b_w_pl,location):\n",
        "    ''' Takes a (bucket_id, [(w0, posting_list_0), (w1, posting_list_1), ...]) \n",
        "    and writes it out to disk as files named {bucket_id}_XXX.bin under the \n",
        "    current directory. Returns a posting locations dictionary that maps each \n",
        "    word to the list of files and offsets that contain its posting list.\n",
        "    Parameters:\n",
        "    -----------\n",
        "      b_w_pl: tuple\n",
        "        Containing a bucket id and all (word, posting list) pairs in that bucket\n",
        "        (bucket_id, [(w0, posting_list_0), (w1, posting_list_1), ...])\n",
        "    Return:\n",
        "      posting_locs: dict\n",
        "        Posting locations for each of the words written out in this bucket.\n",
        "    '''\n",
        "    posting_locs = defaultdict(list)\n",
        "    bucket, list_w_pl = b_w_pl\n",
        "\n",
        "    with closing(MultiFileWriter(location, bucket)) as writer:\n",
        "      for w, pl in list_w_pl: \n",
        "        # convert to bytes\n",
        "        b = b''.join([(doc_id << 16 | (tf & TF_MASK)).to_bytes(TUPLE_SIZE, 'big')\n",
        "                      for doc_id, tf in pl])\n",
        "        # write to file(s)\n",
        "        locs = writer.write(b)\n",
        "      # save file locations to index\n",
        "        posting_locs[w].extend(locs)\n",
        "    return posting_locs"
      ],
      "metadata": {
        "id": "LpAlNcW2wGwv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pyspark crap and getting data from the bucket"
      ],
      "metadata": {
        "id": "aTO0Fd5I-OpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt-get update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!pip install -q graphframes\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "graphframes_jar = 'https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar'\n",
        "spark_jars = '/usr/local/lib/python3.7/dist-packages/pyspark/jars'\n",
        "!wget -N -P $spark_jars $graphframes_jar\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from graphframes import *\n"
      ],
      "metadata": {
        "id": "fWXXi_uK0E4P",
        "outputId": "2dacb214-7979-4e50-95b8-d6447947efe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 39 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 62.0 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,822 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [746 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,238 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,922 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.5 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.7 kB]\n",
            "Fetched 9,738 kB in 5s (1,941 kB/s)\n",
            "Reading package lists... Done\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155225 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "\u001b[K     |████████████████████████████████| 154 kB 6.6 MB/s \n",
            "\u001b[?25h--2022-01-04 18:05:52--  https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar\n",
            "Resolving repos.spark-packages.org (repos.spark-packages.org)... 13.32.87.119, 13.32.87.68, 13.32.87.12, ...\n",
            "Connecting to repos.spark-packages.org (repos.spark-packages.org)|13.32.87.119|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 247880 (242K) [binary/octet-stream]\n",
            "Saving to: ‘/usr/local/lib/python3.7/dist-packages/pyspark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar’\n",
            "\n",
            "graphframes-0.8.2-s 100%[===================>] 242.07K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-01-04 18:05:53 (4.08 MB/s) - ‘/usr/local/lib/python3.7/dist-packages/pyspark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar’ saved [247880/247880]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing spark context\n",
        "# create a spark context and session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "sc.addPyFile(str(Path(spark_jars) / Path(graphframes_jar).name))\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "QmDBuCAj-MHY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copying Wikidata"
      ],
      "metadata": {
        "id": "mo2yEIOX8u95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate your user\n",
        "# The authentication should be done with the email connected to your GCP account\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "-HA-zidH8yZ5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy one wikidumps files \n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import auth\n",
        "\n",
        "project_id = 'core-period-321814'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "data_bucket_name = 'wikidata_preprocessed'\n",
        "try:\n",
        "    if os.environ[\"wikidata_preprocessed\"] is not None:\n",
        "        pass  \n",
        "except:\n",
        "      !mkdir wikidumps\n",
        "      !gsutil cp gs://{data_bucket_name}/multistream1_preprocessed.parquet \"wikidumps/\" \n"
      ],
      "metadata": {
        "id": "tSEWv75R8zOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b940035-7aa2-4102-a407-2759d72aae09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [core-period-321814] or it does not exist.\n",
            "Copying gs://wikidata_preprocessed/multistream1_preprocessed.parquet...\n",
            "| [1 files][316.7 MiB/316.7 MiB]                                                \n",
            "Operation completed over 1 objects/316.7 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#getting wiki data"
      ],
      "metadata": {
        "id": "VEM0wf9mAdTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path \n",
        "import os\n",
        "\n",
        "try:\n",
        "    if os.environ[\"wikidata_preprocessed\"] is not None:\n",
        "      path = os.environ[\"wikidata_preprocessed\"]+\"/wikidumps/*\"\n",
        "except:\n",
        "      path = \"wikidumps/*\"\n",
        "\n",
        "parquetFile = spark.read.parquet(path)\n",
        "wiki_data_body = parquetFile.select(\"id\",\"text\").rdd.filter(lambda x: x[0] in doc_lst)\n",
        "wiki_data_anchor = parquetFile.select(\"id\",\"anchor_text\").rdd.filter(lambda x: x[0] in doc_lst)\n",
        "wiki_data_title = parquetFile.select(\"id\",\"title\").rdd.filter(lambda x: x[0] in doc_lst)\n"
      ],
      "metadata": {
        "id": "rU7XuQDj84K5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tf,df and other helpers"
      ],
      "metadata": {
        "id": "_H4UmiLSAGA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_stopwords = frozenset(stopwords.words('english'))\n",
        "corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", #TODO: CHECK IF NEED TO ADD\n",
        "                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n",
        "                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n",
        "                    \"many\", \"however\", \"would\", \"became\"]\n",
        "all_stopwords = english_stopwords.union(corpus_stopwords)\n",
        "RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n",
        "\n",
        "NUM_BUCKETS = 124\n",
        "def token2bucket_id(token):\n",
        "  return int(_hash(token),16) % NUM_BUCKETS\n",
        "\n",
        "def getLenOfText(text):\n",
        "  return len([token.group() for token in RE_WORD.finditer(text.lower())])\n",
        "# Calc TF\n",
        "# Returns a list of (token, (doc_id, tf)) pairs for each token (word) in the text\n",
        "def word_count(id,text):\n",
        "  ''' Count the frequency of each word in `text` (tf) that is not included in \n",
        "  `all_stopwords` and return entries that will go into our posting lists. \n",
        "  Parameters:\n",
        "  -----------\n",
        "    text: str\n",
        "      Text of one document\n",
        "    id: int\n",
        "      Document id\n",
        "  Returns:\n",
        "  --------\n",
        "    List of tuples\n",
        "      A list of (token, (doc_id, tf)) pairs \n",
        "      for example: [(\"Anarchism\", (12, 5)), ...]\n",
        "  '''\n",
        "  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n",
        " \n",
        "  terms = {}\n",
        "  tf = Counter()\n",
        "  for token in tokens:\n",
        "    if token in all_stopwords:\n",
        "      continue\n",
        "    current = tf.get(token, 0)\n",
        "    tf[token] = current + 1\n",
        "    terms[token] = (id,current +1)\n",
        "\n",
        "\n",
        "  return list(terms.items())\n",
        "\n",
        "# Returns a sorted posting list from an unsorted posting list. Sorting by tf of doc id\n",
        "def reduce_word_counts(unsorted_pl):\n",
        "  ''' Returns a sorted posting list by wiki_id.\n",
        "  Parameters:\n",
        "  -----------\n",
        "    unsorted_pl: list of tuples\n",
        "      A list of (wiki_id, tf) tuples \n",
        "  Returns:\n",
        "  --------\n",
        "    list of tuples\n",
        "      A sorted posting list.\n",
        "  '''\n",
        "\n",
        "  return(sorted(unsorted_pl, key = lambda x: x[0]))\n",
        "\n",
        "def calculate_df(postings):\n",
        "  ''' Takes a posting list RDD and calculate the df for each token.\n",
        "  Parameters:\n",
        "  -----------\n",
        "    postings: RDD\n",
        "      An RDD where each element is a (token, posting_list) pair.\n",
        "  Returns:\n",
        "  --------\n",
        "    RDD\n",
        "      An RDD where each element is a (token, df) pair.\n",
        "  '''\n",
        "  # YOUR CODE HERE\n",
        "  return postings.map(lambda x: (x[0],len(x[1]))).partitionBy(16)\n",
        "\n",
        "def partition_postings_and_write(postings,location):\n",
        "  ''' A function that partitions the posting lists into buckets, writes out \n",
        "  all posting lists in a bucket to disk, and returns the posting locations for \n",
        "  each bucket. Partitioning should be done through the use of `token2bucket` \n",
        "  above. Writing to disk should use the function  `write_a_posting_list`, a \n",
        "  static method implemented in inverted_index_colab.py under the InvertedIndex \n",
        "  class. \n",
        "  Parameters:\n",
        "  -----------\n",
        "    postings: RDD\n",
        "      An RDD where each item is a (w, posting_list) pair.\n",
        "  Returns:\n",
        "  --------\n",
        "    RDD\n",
        "      An RDD where each item is a posting locations dictionary for a bucket. The\n",
        "      posting locations maintain a list for each word of file locations and \n",
        "      offsets its posting list was written to. See `write_a_posting_list` for \n",
        "      more details.\n",
        "  '''\n",
        "  res = defaultdict(list)\n",
        "  output_list = []\n",
        "  bucketed_postings = postings.map(lambda x:(token2bucket_id(x[0]),x)).groupByKey()\n",
        "  for id,content in bucketed_postings.toLocalIterator():\n",
        "    #output_list.append(InvertedIndex.write_a_posting_list((id,content),\"208994616\")) #for gcp ########################################################\n",
        "    output_list.append(InvertedIndex.write_a_posting_list((id,content),location))\n",
        "  sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
        "  return sc.parallelize(output_list,numSlices=16)"
      ],
      "metadata": {
        "id": "LAufaR--XYOQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#building the index : <font color='red'>no need</font>\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "Fi_k6ZuUAikc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_base_path='./drive/MyDrive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsVPqx4b_IHV",
        "outputId": "2f21e3af-221a-473d-d83f-2988269a0db6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(drive_base_path+\"title_index/\"+'title_DL.json', 'rt') as f:\n",
        "  title_DL = json.load(f)\n",
        "with open(drive_base_path+\"anchor_index/\"+'anchor_DL.json', 'rt') as f:\n",
        "  anchor_DL = json.load(f)\n",
        "with open(drive_base_path+\"body_index/\"+'body_DL.json', 'rt') as f:\n",
        "  body_DL = json.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "v7oRmkHR_Vs8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_index_big=InvertedIndex.read_index(drive_base_path+'title_index', 'index')\n",
        "anchor_index_big=InvertedIndex.read_index(drive_base_path+'anchor_index', 'index')\n",
        "body_index_big=InvertedIndex.read_index(drive_base_path+'body_index', 'index')\n",
        "\n",
        "# !cp drive_base_path+'body_index'"
      ],
      "metadata": {
        "id": "disBA4g8LaNG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_idf(t,d,DL):\n",
        "  pls_lst=find_postings(t,index)[t]\n",
        "  lst= [tf for doc,tf in pls_lst if d==doc]\n",
        "  term_freq_not_normelized=lst[0]\n",
        "  D=DL[d]\n",
        "  tf=term_freq_not_normelized/D\n",
        "  N=len(DL)\n",
        "  idf=math.log2(N/index.df[t])\n",
        "  return tf*idf"
      ],
      "metadata": {
        "id": "qxNi4ddcwoUY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_data_body.first()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFANK1VfSI6t",
        "outputId": "56f1343a-70d8-4628-dc1f-fb692c609f13"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(id=1857, text='thumb|right|On an approval ballot, the voter can select any number of candidates.\\n\\'\\'\\'Approval voting\\'\\'\\' is an electoral system where each voter may select (\"approve\") any number of candidates, and the winner is the candidate approved by the largest number of voters. It is distinct from plurality voting, in which a voter may choose only one option among several, whereby the option with the most votes is chosen. It is related to score voting in which voters give each option a score on a scale, and the option with the highest total of scores is selected. Approval voting can also be used in multiwinner elections; see multiwinner approval voting.\\n\\nProposals to implement approval voting for municipal elections in the United States, were approved in referendums in Fargo, North Dakota, in 2018, and St. Louis, Missouri, in 2020. Fargo used approval voting in June 2020 to elect two at-large seats on its city council, and St. Louis used it to advance two candidates in March 2021 nonpartian primaries for mayor and aldermen.\\n\\n Description \\n\\nApproval voting ballots show a list of the candidates running for that seat for each office being contested. Next to each name is a checkbox (or another similar way to mark \"Yes\" or \"No\" for that candidate).\\n\\nEach candidate may be treated as a separate question: \"Do you approve of this person for the job?\" Approval voting lets each voter indicate support for one, some, or all candidates. All votes count equally, and everyone gets the same number of votes: one vote per candidate, either for or against. Final tallies show how many voters support each candidate, and the winner is the candidate whom the most voters support.\\n\\nBallots on which the voter marked every candidate the same (whether yes or no) usually have no effect on the outcome of the election. Each ballot separates candidates into two groups: those supported and those that are not. Each candidate approved is considered preferred to any candidate not approved, while the voter\\'s preferences among approved candidates is unspecified, and likewise, the voter\\'s preferences among unapproved candidates is also unspecified.\\n Usage \\n Current use \\nIn 2018, Fargo, North Dakota, passed a local ballot initiative adopting approval voting for the city\\'s local elections, and it was used to elect officials in June 2020, becoming the first United States city and jurisdiction to adopt approval voting.\\n\\nIn November 2020, St. Louis, Missouri passed Proposition D to authorize a variant of approval voting (as unified primary) for municipal offices.\\n\\nHistory  \\n300px|thumb|Rows of secret approval vote boxes from early 1900s Greece, where the voter drops a marble to the right or left of the box, through a tube, one for each candidate standing\\nRobert J. Weber coined the term \"approval voting\" in 1971. It was more fully published in 1978 by political scientist Steven Brams and mathematician Peter Fishburn.\\n\\nHistorically, several voting methods that incorporate aspects of approval voting have been used:\\n\\n Approval voting was used for papal conclaves between 1294 and 1621, with an average of about forty cardinals engaging in repeated rounds of voting until one candidate was listed on at least two-thirds of ballots.  Josep Colomer writes of the 1559 conclave when a cardinal nearly won when an ally met confidentially with cardinals and asked them for a \"token\" approval vote for his friend to avoid a shut out – and then the cardinal came close to winning with votes on 17 of 32 ballots.\\n In the 13th through 18th centuries, the Republic of Venice elected the Doge of Venice using a multi-stage process that featured random selection and voting that allowed approval of multiple candidates and required a supermajority.\\n According to Steven J. Brams, approval voting was used for unspecified elections in 19th century England.\\n The selection of the Secretary-General of the United Nations has involved \"straw poll\" rounds of approval polling to help discover and build a consensus before a formal vote is held in the Security Council. The United Nations Secretary-General selection, 2006 indicated that South Korean Foreign Minister Ban Ki-moon was the only candidate to be acceptable to all five permanent members of the Security Council, which led to the withdrawal of India\\'s Shashi Tharoor, who had the highest overall approval rate.\\nApproval voting was used in Greek legislative elections from 1864 to 1923, when it was replaced with proportional representation.\\n\\n Political organizations and jurisdictions \\nApproval voting has been used in privately administered nomination contests by the Independent Party of Oregon in 2011, 2012, 2014, and 2016. Oregon is a fusion voting state, and the party has cross-nominated legislators and statewide officeholders using this method; its 2016 presidential preference primary did not identify a potential nominee due to no candidate earning more than 32% support. The party switched to using STAR voting in 2020.\\n\\nIt is also used in internal elections by the American Solidarity Party, the Green Parties of Texas and Ohio, the Libertarian parties of Texas and Colorado, the US Modern Whig party, and the German Pirate Party.\\n\\nIn 2018, Fargo, North Dakota passed a ballot initiative adopting approval voting for local elections, becoming the first US city and jurisdiction to adopt approval voting.  (A previous city commissioner election in 2015 suffered from six-way vote-splitting, resulting in a candidate winning with only a 22% plurality of the vote.) The first election was held June 9, 2020, selecting two city commissioners.  Both winners received over 50% approval, with an average 2.3 approvals per ballot, and 62% of voters supported the change to approval voting in a poll. A poll by opponents of approval voting was conducted to test whether voters had in fact voted strategically according to the Burr dilemma. They found that 30% of voters who bullet voted did so for strategic reasons, while 57% did so because it was their sincere opinion. \\n\\nIn 2020, St. Louis, Missouri passed an initiative to adopt approval voting followed by a top-two runoff (see Unified primary), thus becoming the second US city to adopt approval voting and the first to use a variant of it.  The first such primary was held in March 2021, and unofficial results showed voters expressed 1.1 to 1.6 approvals per ballot, in races with more than two candidates.\\n\\n Other organizations \\nThe idea of approval was adopted by X. Hu and Lloyd Shapley in 2003 in studying authority distribution in organizations.\\n\\nApproval voting has been adopted by several learned societies: the Society for Social Choice and Welfare (1992), Mathematical Association of America (1986), the American Mathematical Society, the Institute of Management Sciences (1987) (now the Institute for Operations Research and the Management Sciences), the American Statistical Association (1987), and the Institute of Electrical and Electronics Engineers (1987). The IEEE board in 2002 rescinded its decision to use approval voting. IEEE Executive Director Daniel J. Senese stated that approval voting was abandoned because \"few of our members were using it and it was felt that it was no longer needed.\" Because none of these associations report results to their members and the public, it is difficult to evaluate Senese\\'s claim and whether it is also true of other associations; Steven Brams\\' analysis of the 5-candidate 1987 Mathematical Association of America presidential election shows that 79% of voters cast a ballot for one candidate, 16% for 2 candidates, 5% for 3, and 1% for 4, with the winner earning the approval of 1,267 (32%) of 3,924 voters.\\n\\nApproval voting was used for Dartmouth Alumni Association elections for seats on the College Board of Trustees, but after some controversy it was replaced with traditional runoff elections by an alumni vote of 82% to 18% in 2009. Dartmouth students started to use approval voting to elect their student body president in 2011. In the first election, the winner secured the support of 41% of voters against several write-in candidates. In 2012, Suril Kantaria won with the support of 32% of the voters. In 2013, 2014 and 2016, the winners also earned the support of under 40% of the voters. Results reported in \\'\\'The Dartmouth\\'\\' show that in the 2014 and 2016 elections, more than 80 percent of voters approved of only one candidate. Students replaced approval voting with plurality voting before the 2017 elections.\\n\\nApproval voting also can be used in social scenarios as a fairer, but still quick system compared to a First-Past-The-Post equivalent, being able to avoid a spoiler effect while being very quick to calculate.\\n\\nSee also: Multiwinner approval voting#Usage.\\n\\n Effect on elections \\n\\nApproval voting advocates Steven Brams and Dudley R. Herschbach predict that approval voting should increase voter participation, prevent minor-party candidates from being spoilers, and reduce negative campaigning. The effect of this system as an electoral reform measure is not without critics, however. FairVote has a position paper arguing that approval voting has three flaws that undercut it as a method of voting and political vehicle. They argue that it can result in the defeat of a candidate who would win an absolute majority in a plurality election, can allow a candidate to win who might not win \\'\\'any\\'\\' support in a plurality election, and has incentives for tactical voting.  The first two \"flaws\" are considered advantages by advocates of approval voting, as it chooses centrist candidates with broad appeal rather than polarizing candidates who appeal only to the majority. Supporters also point out that any voting method is subject to tactical voting with more than two candidates, as pointed out in Gibbard\\'s theorem.\\n\\nOne study showed that approval voting would not have chosen the same two winners as plurality voting (Chirac and Le Pen) in France\\'s presidential election of 2002 (first round) – it instead would have chosen Chirac and Jospin as the top two to proceed to a runoff. Le Pen lost by a very high margin in the runoff, 82.2% to 17.8%, a sign that the true top two had not been found. Straight approval voting without a runoff, from the study, still would have selected Chirac, but with an approval percentage of only 36.7%, compared to Jospin at 32.9%. Le Pen, in that study, would have received 25.1%. In the real primary election, the top three were Chirac, 19.9%, Le Pen, 16.9%, and Jospin, 16.2%. A study of various \"evaluative voting\" methods (approval voting and score voting) during the French presidential election, 2012 showed that \"unifying\" candidates tended to do better, and polarizing candidates did worse, via the evaluative voting methods than via the plurality system.\\n\\nA generalized version of the Burr dilemma applies to approval voting when two candidates are appealing to the same subset of voters.  Although approval voting differs from the voting system used in the Burr dilemma, approval voting can still leave candidates and voters with the generalized dilemma of whether to compete or cooperate.\\n\\nWhile in the modern era there have been relatively few competitive approval voting elections where tactical voting is more likely, Brams argues that approval voting usually elects Condorcet winners in practice. Critics of the use of approval voting in the alumni elections for the Dartmouth Board of Trustees in 2009 placed its ultimately successful repeal before alumni voters, arguing that the system has not been electing the most centrist candidates. \\'\\'The Dartmouth\\'\\' editorialized that \"When the alumni electorate fails to take advantage of the approval voting process, the three required Alumni Council candidates tend to split the majority vote, giving petition candidates an advantage. By reducing the number of Alumni Council candidates, and instituting a more traditional one-person, one-vote system, trustee elections will become more democratic and will more accurately reflect the desires of our alumni base.\"\\n\\n Strategic voting \\n\\n Overview \\nApproval voting allows voters to select all the candidates whom they consider to be reasonable choices.\\n\\n\\'\\'Strategic approval\\'\\' voting differs from ranked choice voting methods where voters might \\'\\'reverse\\'\\' the preference order of two options, which if done on a larger scale causes an unpopular candidate to win. Strategic Approval voting, with more than two options, involves the voter changing their approval threshold. The voter decides which options to give the \\'\\'same\\'\\' rating, even if they were to have a preference order between them.\\n\\nApproval voting allows for bullet voting and compromising,  while it is immune to push-over and burying.\\n\\nBullet Voting occurs when a voter approves \\'\\'only\\'\\' candidate \\'a\\' instead of \\'\\'both\\'\\' \\'a\\' and \\'b\\' for the reason that voting for \\'b\\' can cause \\'a\\' to lose. The voter would be satisfied with either \\'a\\' or \\'b\\' but has a moderate preference for \\'a\\'. Were \\'b\\' to win, this hypothetical voter would still be satisfied.\\n\\nCompromising occurs when a voter approves an \\'\\'additional\\'\\' candidate who is otherwise considered unacceptable to the voter to prevent an even worse alternative from winning.\\n\\n Sincere voting \\nApproval voting experts describe sincere votes as those \"... that directly reflect the true preferences of a voter, i.e., that do not report preferences \\'falsely.\\'\"  They also give a specific definition of a sincere approval vote in terms of the voter\\'s ordinal preferences as being any vote that, if it votes for one candidate, it also votes for any more preferred candidate.  This definition allows a sincere vote to treat strictly preferred candidates the same, ensuring that every voter has at least one sincere vote. The definition also allows a sincere vote to treat equally preferred candidates differently.  When there are two or more candidates, every voter has at least three sincere approval votes to choose from.  Two of those sincere approval votes do not distinguish between any of the candidates: vote for none of the candidates and vote for all of the candidates.  When there are three or more candidates, every voter has more than one sincere approval vote that distinguishes between the candidates.\\n\\n Examples \\n\\nBased on the definition above, if there are four candidates, A, B, C, and D, and a voter has a strict preference order, preferring A to B to C to D, then the following are the voter\\'s possible sincere approval votes:\\nvote for A, B, C, and D\\nvote for A, B, and C\\nvote for A and B\\nvote for A\\nvote for no candidates\\n\\nIf the voter instead equally prefers B and C, while A is still the most preferred candidate and D is the least preferred candidate, then all of the above votes are sincere and the following combination is also a sincere vote:\\nvote for A and C\\n\\nThe decision between the above ballots is equivalent to deciding an arbitrary \"approval cutoff.\" All candidates preferred to the cutoff are approved, all candidates less preferred are not approved, and any candidates equal to the cutoff may be approved or not arbitrarily.\\n\\n Sincere strategy with ordinal preferences \\n\\nA sincere voter with multiple options for voting sincerely still has to choose which sincere vote to use. Voting strategy is a way to make that choice, in which case strategic approval voting includes sincere voting, rather than being an alternative to it. This differs from other voting systems that typically have a unique sincere vote for a voter.\\n\\nWhen there are three or more candidates, the winner of an approval voting election can change, depending on which sincere votes are used. In some cases, approval voting can sincerely elect any one of the candidates, including a Condorcet winner and a Condorcet loser, without the voter preferences changing.  To the extent that electing a Condorcet winner and not electing a Condorcet loser is considered desirable outcomes for a voting system, approval voting can be considered vulnerable to sincere, strategic voting.  In one sense, conditions where this can happen are robust and are not isolated cases.  On the other hand, the variety of possible outcomes has also been portrayed as a virtue of approval voting, representing the flexibility and responsiveness of approval voting, not just to voter ordinal preferences, but cardinal utilities as well.\\n\\n Dichotomous preferences \\n\\nApproval voting avoids the issue of multiple sincere votes in special cases when voters have dichotomous preferences. For a voter with dichotomous preferences, approval voting is strategy-proof (also known as strategy-free).  When all voters have dichotomous preferences and vote the sincere, strategy-proof vote, approval voting is guaranteed to elect the Condorcet winner, if one exists.  However, having dichotomous preferences when there are three or more candidates is not typical.  It is an unlikely situation for all voters to have dichotomous preferences when there are more than a few voters.\\n\\nHaving dichotomous preferences means that a voter has bi-level preferences for the candidates.  All of the candidates are divided into two groups such that the voter is indifferent between any two candidates in the same group and any candidate in the top-level group is preferred to any candidate in the bottom-level group.  A voter that has strict preferences between three candidates—prefers A to B and B to C—does not have dichotomous preferences.\\n\\nBeing strategy-proof for a voter means that there is a unique way for the voter to vote that is a strategically best way to vote, regardless of how others vote. In approval voting, the strategy-proof vote, if it exists, is a sincere vote.\\n Approval threshold \\n\\nAnother way to deal with multiple sincere votes is to augment the ordinal preference model with an approval or acceptance threshold.  An approval threshold divides all of the candidates into two sets, those the voter approves of and those the voter does not approve of.  A voter can approve of more than one candidate and still prefer one approved candidate to another approved candidate.  Acceptance thresholds are similar.  With such a threshold, a voter simply votes for every candidate that meets or exceeds the threshold.\\n\\nWith threshold voting, it is still possible to not elect the Condorcet winner and instead elect the Condorcet loser when they both exist.  However, according to Steven Brams, this represents a strength rather than a weakness of approval voting.  Without providing specifics, he argues that the pragmatic judgements of voters about which candidates are acceptable should take precedence over the Condorcet criterion and other social choice criteria.\\n\\n Strategy with cardinal utilities \\n\\nVoting strategy under approval is guided by two competing features of approval voting.  On the one hand, approval voting fails the later-no-harm criterion, so voting for a candidate can cause that candidate to win instead of a candidate more preferred by that voter.  On the other hand, approval voting satisfies the monotonicity criterion, so not voting for a candidate can never help that candidate win, but can cause that candidate to lose to a less preferred candidate.  Either way, the voter can risk getting a less preferred election winner.  A voter can balance the risk-benefit trade-offs by considering the voter\\'s cardinal utilities, particularly via the von Neumann–Morgenstern utility theorem, and the probabilities of how others vote.\\n\\nA rational voter model described by Myerson and Weber specifies an approval voting strategy that votes for those candidates that have a positive prospective rating.  This strategy is optimal in the sense that it maximizes the voter\\'s expected utility, subject to the constraints of the model and provided the number of other voters is sufficiently large.\\n\\nAn optimal approval vote always votes for the most preferred candidate and not for the least preferred candidate.  However, an optimal vote can require voting for a candidate and not voting for a more preferred candidate if there 4 candidates or more.\\n\\nOther strategies are also available and coincide with the optimal strategy in special situations.  For example:\\n Vote for the candidates that have above average utility.  This strategy coincides with the optimal strategy if the voter thinks that all pairwise ties are equally likely\\n Vote for any candidate that is more preferred than the expected winner and also vote for the expected winner if the expected winner is more preferred than the expected runner-up.  This strategy coincides with the optimal strategy if there are three or fewer candidates or if the pivot probability for a tie between the expected winner and expected runner-up is sufficiently large compared to the other pivot probabilities.\\nVote for the most preferred candidate only.  This strategy coincides with the optimal strategy when there is only one candidate with a positive prospective rating.\\n\\nAnother strategy is to vote for the top half of the candidates, the candidates that have an above-median utility. When the voter thinks that others are balancing their votes randomly and evenly, the strategy maximizes the voter\\'s power or efficacy, meaning that it maximizes the probability that the voter will make a difference in deciding which candidate wins.\\n\\nOptimal strategic approval voting fails to satisfy the Condorcet criterion and can elect a Condorcet loser.  Strategic approval voting can guarantee electing the Condorcet winner in some special circumstances.  For example, if all voters are rational and cast a strategically optimal vote based on a common knowledge of how all the other voters vote except for small-probability, statistically independent errors in recording the votes, then the winner will be the Condorcet winner, if one exists.\\n\\n Strategy examples \\nIn the example election described here, assume that the voters in each faction share the following von Neumann–Morgenstern utilities, fitted to the interval between 0 and 100.  The utilities are consistent with the rankings given earlier and reflect a strong preference each faction has for choosing its city, compared to weaker preferences for other factors such as the distance to the other cities.\\n\\n+Voter utilities for each candidate city \\xa0  Candidates  \\xa0 Fraction of voters(living close to) Memphis Nashville Chattanooga Knoxville Average Memphis (42%) 100  15  10  0  31.25 Nashville (26%) 0  100  20  15  33.75 Chattanooga (15%) 0  15  100  35  37.5 Knoxville (17%) 0  15  40  100  38.75\\n\\nUsing these utilities, voters choose their optimal strategic votes based on what they think the various pivot probabilities are for pairwise ties.  In each of the scenarios summarized below, all voters share a common set of pivot probabilities.\\n\\n+Approval voting results  for scenarios using optimal strategic voting \\xa0  Candidate vote totals Strategy scenario Winner Runner-up Memphis Nashville Chattanooga Knoxville Zero-info Memphis  Chattanooga  42  26  32  17 Memphis leading Chattanooga Three-way tie  42  58  58  58 Chattanooga leading Knoxville Chattanooga  Nashville  42  68  83  17 Chattanooga leading Nashville Nashville  Memphis  42  68  32  17 Nashville leading Memphis Nashville  Memphis  42  58  32  32\\n\\nIn the first scenario, voters all choose their votes based on the assumption that all pairwise ties are equally likely.  As a result, they vote for any candidate with an above-average utility.  Most voters vote for only their first choice.  Only the Knoxville faction also votes for its second choice, Chattanooga.  As a result, the winner is Memphis, the Condorcet loser, with Chattanooga coming in second place.  In this scenario, the winner has minority approval (more voters disapproved than approved) and all the others had even less support, reflecting the position that no choice gave an above-average utility to a majority of voters.\\n\\nIn the second scenario, all of the voters expect that Memphis is the likely winner, that Chattanooga is the likely runner-up, and that the pivot probability for a Memphis-Chattanooga tie is much larger than the pivot probabilities of any other pair-wise ties.  As a result, each voter votes for any candidate they prefer more than the leading candidate, and also vote for the leading candidate if they prefer that candidate more than the expected runner-up. Each remaining scenario follows a similar pattern of expectations and voting strategies.\\n\\nIn the second scenario, there is a three-way tie for first place.  This happens because the expected winner, Memphis, was the Condorcet loser and was also ranked last by any voter that did not rank it first.\\n\\nOnly in the last scenario does the actual winner and runner-up match the expected winner and runner-up.  As a result, this can be considered a stable strategic voting scenario. In the language of game theory, this is an \"equilibrium.\"  In this scenario, the winner is also the Condorcet winner.\\n\\nDichotomous cutoff\\nAs this voting method is cardinal rather than ordinal, it is possible to model voters in a way that does not simplify to an ordinal method. Modelling voters with a \\'dichotomous cutoff\\' assumes a voter has an immovable approval cutoff, while having meaningful cardinal preferences. This means that rather than voting for their top 3 candidates, or all candidates above the average approval (which may result in their vote changing if one candidate drops out, resulting in a system that does not satisfy IIA), they instead vote for all candidates above a certain approval \\'cutoff\\' that they have decided. This cutoff does not change, regardless of which and how many candidates are running, so when all available alternatives are either above or below the cutoff, the voter votes for all or none of the candidates, despite preferring some over others.  This could be imagined to reflect a case where many voters become disenfranchised and apathetic if they see no candidates they approve of. In a case such as this, many voters may have an internal cutoff, and would not simply vote for their top 3, or the above average candidates, although that is not to say that it is necessarily entirely immovable.\\n\\nFor example, in this scenario, voters are voting for candidates with approval above 50% (bold signifies that the voters voted for the candidate):\\n\\n Proportion of electorate Approval of Candidate A Approval of Candidate B Approval of Candidate C Approval of Candidate D Average approval 25% \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  40%  10%  \\'\\'50%\\'\\' 35% 10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  40%  \\'\\'50%\\'\\' 30% 40%  10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  \\'\\'50%\\'\\' 10% \\'\\'\\'60%\\'\\'\\'  40%  10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'50%\\'\\'\\n\\nC wins with 65% of the voters\\' approval, beating B with 60%, D with 40% and A with 35%\\n\\nIf voters\\' threshold for receiving a vote is that the candidate has an above average approval, or they vote for their two most approved of candidates, this is not a dichotomous cutoff, as this can change if candidates drop out.  On the other hand, if voters\\' threshold for receiving a vote is fixed (say 50%), this is a dichotomous cutoff, and satisfies IIA as shown below:\\n\\n+ A drops out, candidates voting for above average approval Proportion of electorate Approval of Candidate A Approval of Candidate B Approval of Candidate C Approval of Candidate D Average approval 25% –  \\'\\'\\'60%\\'\\'\\'  \\'\\'\\'40%\\'\\'\\'  10%  \\'\\'37%\\'\\' 35% –  \\'\\'\\'90%\\'\\'\\'  60%  40%  \\'\\'63%\\'\\' 30% –  10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  \\'\\'53%\\'\\' 10% –  40%  10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'47%\\'\\'\\nB now wins with 60%, beating C with 55% and D with 40%\\n+ A drops out, candidates voting for approval > 50% Proportion of electorate Approval of Candidate A Approval of Candidate B Approval of Candidate C Approval of Candidate D Average approval 25% –  \\'\\'\\'60%\\'\\'\\'  40%  10%  \\'\\'37%\\'\\' 35% –  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  40%  \\'\\'63%\\'\\' 30% –  10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  \\'\\'53%\\'\\' 10% –  40%  10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'47%\\'\\'\\nWith dichotomous cutoff, C still wins.\\n\\n+ D drops out, candidates voting for top 2 candidates Proportion of electorate Approval of Candidate A Approval of Candidate B Approval of Candidate C Approval of Candidate D Average approval 25% \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  40%  –  \\'\\'63%\\'\\' 35% 10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  –  \\'\\'53%\\'\\' 30% \\'\\'\\'40%\\'\\'\\'  10%  \\'\\'\\'90%\\'\\'\\'  –  \\'\\'47%\\'\\' 10% \\'\\'\\'60%\\'\\'\\'  \\'\\'\\'40%\\'\\'\\'  10%  –  \\'\\'37%\\'\\'\\nB now wins with 70%, beating C and A with 65%\\n+ D drops out, candidates voting for approval > 50% Proportion of electorate Approval of Candidate A Approval of Candidate B Approval of Candidate C Approval of Candidate D Average approval 25% \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  40%  –  \\'\\'63%\\'\\' 35% 10%  \\'\\'\\'90%\\'\\'\\'  \\'\\'\\'60%\\'\\'\\'  –  \\'\\'53%\\'\\' 30% 40%  10%  \\'\\'\\'90%\\'\\'\\'  –  \\'\\'47%\\'\\' 10% \\'\\'\\'60%\\'\\'\\'  40%  10%  –  \\'\\'37%\\'\\'\\nWith dichotomous cutoff, C still wins.\\n\\n Compliance with voting system criteria \\nMost of the mathematical criteria by which voting systems are compared were formulated for voters with ordinal preferences. In this case, approval voting requires voters to make an additional decision of where to put their approval cutoff (see examples above). Depending on how this decision is made, approval voting satisfies different sets of criteria.\\n\\nThere is no ultimate authority on which criteria should be considered, but the following are criteria that many voting theorists accept and consider desirable:\\n Unrestricted domain—A voter may have any preference ordering among the alternatives.\\n Non-dictatorship—There does not exist a single voter whose preference for the alternatives always determines the outcome regardless of other voters\\' preferences.\\n Pareto efficiency—If every voter prefers candidate A to all other candidates, then A must be elected. (from Arrow\\'s impossibility theorem)\\n Majority criterion—If there exists a majority that ranks (or rates) a single candidate higher than all other candidates, does that candidate always win?\\n Monotonicity criterion—Is it impossible to cause a winning candidate to lose by ranking that candidate higher, or to cause a losing candidate to win by ranking that candidate lower?\\n Consistency criterion—If the electorate is divided in two and a choice wins in both parts, does it always win overall?\\n Participation criterion—Is voting honestly always better than not voting at all? (This is grouped with the distinct but similar Consistency Criterion in the table below.)\\n Condorcet criterion—If a candidate beats every other candidate in pairwise comparison, does that candidate always win? (This implies the majority criterion, above)\\n Condorcet loser criterion—If a candidate loses to every other candidate in pairwise comparison, does that candidate always lose?\\n Independence of irrelevant alternatives—Is the outcome the same after adding or removing non-winning candidates?\\n Independence of clones criterion—Is the outcome the same if candidates identical to existing candidates are added?\\n Reversal symmetry—If individual preferences of each voter are inverted, does the original winner never win?\\n\\n  Unrestricted domain  Non-dictatorship  Pareto efficiency  Majority  Monotone  Consistency & Participation  Condorcet  Condorcet loser  IIA  Clone independence  Reversal symmetry Cardinal preferences  Zero information, rational voters Yes Yes No No Yes Yes No No No  No Yes Imperfect information, rational voters Yes Yes No No Yes Yes No No No No Yes Strong Nash equilibrium (Perfect information, rational voters, and perfect strategy) Yes Yes Yes Yes  Yes  No Yes No No  Yes  Yes Absolute dichotomous cutoff Yes No Yes No Yes Yes No No Yes Yes Yes Dichotomous preferences  Rational voters No Yes Yes Yes  Yes  Yes  Yes  Yes  Yes  Yes  Yes\\n\\nApproval voting satisfies the mutual majority criterion and Smith criterion when voters\\' preferences are dichotomous; this is because the winner will be someone that the most voters prefer above all others, or that ties with other candidates but the group of tied candidates is preferred by more voters than any candidate not in the group.\\n\\n Other issues and comparisons \\n\\n Approval voting can allow voters to cast a compromise vote without abandoning their favorite candidate as long as voters accept the potential of that compromise vote resulting in the defeat of their favorite. Plurality voting can lead to voters abandoning their first choice in order to help a \"lesser of evils\" to win.\\n However, approval voting forces voters to face an initial voting tactical decision as to whether to vote for (or \\'\\'approve of\\'\\') their second-choice candidate or not. The voter may want to retain expression of preference of their favorite candidate over their second choice.  But that does not allow the same voter to express preference of their second choice over any other.\\n Approval ballots can be counted by existing machines designed for plurality elections, as ballots are cast, so that final tallies are immediately available after the election, without any upgrades to equipment. Approval counting can be completed at the local level and conveniently summed at the regional or national level.\\n If voters are sincere, approval voting would elect centrists at least as often as moderates of each extreme. If backers of relatively extreme candidates are insincere and \"bullet vote\" for that first choice, they can help that candidate defeat a compromise candidate who would have won if every voter had cast sincere preferences.\\n If voters are sincere, candidates trying to win an approval voting election might need as much as 100% approval to beat a strong competitor, and would have to find solutions that are fair to everyone to do so. However, a candidate may win a plurality race by promising many perks to a simple majority or even a plurality of voters at the expense of the smaller voting groups.\\n Approval voting fails the majority criterion, because a candidate who is preferred by a majority of voters is not always elected. In some cases approval voting will elect a candidate that has greater overall utility than a candidate preferred by a mere majority, if the majority also approves a compromise candidate that includes representation of the minority. In other cases, with elections having three or more candidates, approval voting will fail to elect the candidate with greater overall utility also preferred by a majority, if a less moderate candidate within the majority view gains enough approvals from the majority to win, while core supporters of the less moderate candidate are more selective (i.e. vote only for the extreme candidate), leaving a third sizable minority unrepresented.  It can also fail a different majority criterion in that the winner can win with fewer than half the votes approving. \\n Suppose a candidate is eliminated (say, for medical reasons) between a primary election and the party convention. With plurality voting, voters who supported the eliminated candidate lose their franchise. Approval voting affords representation to voters by counting their approvals among remaining candidates.\\n Approval voting without write-ins is easily reversed as disapproval voting where a choice is disavowed, as is already required in other measures in politics (e.g., representative recall).\\n Unlike plurality voting, approval voting allows voters to block a candidate by voting for several alternatives instead of just one, increasing the probability an alternative wins.\\n In contentious elections with large groups of organized voters who prefer their favorite candidate vastly over all others, approval voting may revert to plurality voting. Some voters support only their single favored candidate when they perceive the other candidates more as competitors to their preferred candidate than as compromise choices. Score voting and Majority Judgment allow these voters to give intermediate approval ratings, but at the cost of added ballot complexity and longer ballot counts.\\n\\n Ballot types \\nApproval ballots can be of at least four semi-distinct forms. The simplest form is a blank ballot on which voters hand-write the names of the candidates they support. A more structured ballot lists all candidates, and voters mark each candidate they support. A more explicit structured ballot can list the candidates and provide two choices by each. (Candidate list ballots can include spaces for write-in candidates as well.)\\n 160px 160px 160px 160px\\n\\nAll four ballots are theoretically equivalent. The more structured ballots may aid voters in offering clear votes so they explicitly know all their choices. The Yes/No format can help to detect an \"undervote\" when a candidate is left unmarked and allow the voter a second chance to confirm the ballot markings are correct. The \"single bubble\" format is incapable of producing invalid ballots (which might otherwise be rejected in counting).\\n\\nUnless the second or fourth format is used, fraudulently adding votes to an approval voting ballot does not invalidate the ballot (that is, it does not make it appear inconsistent). Thus, approval voting raises the importance of ensuring that the \"chain of custody\" of ballots is secure.\\n\\n See also \\n\\n Multiwinner approval voting - a variant of approval voting in which multiple candidates may be elected.\\nParty-approval voting - a variant of approval voting in which voters approve of parties, rather than individual candidates.\\n Score Voting (also called Range voting) - a generalization of approval voting in which each voter can give any score to any voter, rather than just 0 or 1.\\n\\n Notes \\n\\n References \\n\\n Sources \\n \\n\\n External links \\n\\n Approval Voting Article by The Center for Election Science\\n Could Approval Voting Prevent Electoral Disaster? Video by Big Think\\n Approval Voting on Dichotomous Preferences Article by Marc Vorsatz.\\n Scoring Rules on Dichotomous Preferences Article by Marc Vorsatz.\\n The Arithmetic of Voting article by Guy Ottewell\\n Critical Strategies Under Approval Voting: Who Gets Ruled In And Ruled Out Article by Steven J. Brams and M. Remzi Sanver.\\n Quick and Easy Voting for Normal People YouTube video\\n\\nCategory:Single-winner electoral systems\\nCategory:Cardinal electoral systems\\nCategory:Monotonic electoral systems\\nCategory:Electoral systems\\nCategory:Historical rankings of public figures\\nCategory:Rating')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_index_ver1(rdd_data,location,DL,big_index):\n",
        "    \n",
        "    word_counts = rdd_data.flatMap(lambda x: word_count(x[0], x[1],))\n",
        "    DL_RDD=rdd_data.map(lambda x: (x[0],getLenOfText(x[1])))\n",
        "    postings = word_counts.groupByKey().mapValues(reduce_word_counts)\n",
        "    \n",
        "    w2df = calculate_df(postings)\n",
        "    w2df_dict = w2df.collectAsMap()\n",
        "    posting_locs_list = partition_postings_and_write(postings,location).collect()\n",
        "\n",
        "    super_posting_locs = defaultdict(list)\n",
        "    for posting_loc in posting_locs_list:\n",
        "      for k, v in posting_loc.items():\n",
        "        super_posting_locs[k].extend(v)\n",
        "\n",
        "    # Create inverted index instance\n",
        "    inverted = InvertedIndex()\n",
        "    # DL\n",
        "    inverted.DL=DL\n",
        "    # Adding the posting locations dictionary to the inverted index\n",
        "    inverted.posting_locs = super_posting_locs\n",
        "    # Add the token - df dictionary to the inverted index\n",
        "    inverted.df = w2df_dict\n",
        "    # write the global stats out\n",
        "\n",
        "    inverted.write_index(location, 'index')\n",
        "\n",
        "    return inverted\n",
        "\n",
        "index_body=build_index_ver1(wiki_data_body,'./body_index',body_DL)\n",
        "\n",
        "index_title=build_index_ver1(wiki_data_title,'./title_index',title_DL)\n"
      ],
      "metadata": {
        "id": "7LjMM0TGcSjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd3dd36-6b08-44ea-c248-c1f02c799bff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('right', (1857, 2))\n",
            "('approval', (1857, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count_anchor(id,list_of_tupels):\n",
        "  ''' Count the frequency of each word in `text` (tf) that is not included in \n",
        "  `all_stopwords` and return entries that will go into our posting lists. \n",
        "  Parameters:\n",
        "  -----------\n",
        "    text: str\n",
        "      Text of one document\n",
        "    id: int\n",
        "      Document id\n",
        "  Returns:\n",
        "  --------\n",
        "    List of tuples\n",
        "      A list of (token, (doc_id, tf)) pairs \n",
        "      for example: [(\"Anarchism\", (12, 5)), ...]\n",
        "  '''\n",
        "  t=flatten_lst([RE_WORD.finditer(text.lower()) for dest_id,text in list_of_tupels])\n",
        "\n",
        "  tokens = [token.group() for token in t]\n",
        "\n",
        "  terms = {}\n",
        "  tf = Counter()\n",
        "  for token in tokens:\n",
        "    if token in all_stopwords:\n",
        "      continue\n",
        "    current = tf.get(token, 0)\n",
        "    tf[token] = current + 1\n",
        "    terms[token] = (id,current +1)\n",
        "\n",
        "\n",
        "  return list(terms.items())\n",
        "\n",
        "def build_index_ver2(rdd_data,location):\n",
        "    word_counts_body = rdd_data.flatMap(lambda x: word_count_anchor(x[0], x[1]))\n",
        "    postings = word_counts_body.groupByKey().mapValues(reduce_word_counts)\n",
        "    DL_RDD=rdd_data.map(lambda x: (x[0],getLenOfText(x[1])))\n",
        "    w2df = calculate_df(postings)\n",
        "\n",
        "    w2df_dict = w2df.collectAsMap()\n",
        "    posting_locs_list = partition_postings_and_write(postings,location).collect()\n",
        "\n",
        "    super_posting_locs = defaultdict(list)\n",
        "    for posting_loc in posting_locs_list:\n",
        "      for k, v in posting_loc.items():\n",
        "        super_posting_locs[k].extend(v)\n",
        "\n",
        "    # Create inverted index instance\n",
        "    inverted = InvertedIndex()\n",
        "    # DL\n",
        "    inverted.DL=DL_RDD.collectAsMap()\n",
        "    # Adding the posting locations dictionary to the inverted index\n",
        "    inverted.posting_locs = super_posting_locs\n",
        "    # Add the token - df dictionary to the inverted index\n",
        "    inverted.df = w2df_dict\n",
        "    # write the global stats out\n",
        "    inverted.write_index(location, 'index')\n",
        "\n",
        "    return inverted\n",
        "\n",
        "\n",
        "#index_anchor=build_index_ver2(wiki_data_anchor,'./anchor_index')"
      ],
      "metadata": {
        "id": "dCgZEK6zIZD5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexbuilding - Change to \"True\" to build index\n",
        "if False:\n",
        "  print(\"Creating indices folders\")\n",
        "  !mkdir body_index title_index anchor_index\n",
        "  print(\"Building body index.\")\n",
        "  index_body=build_index_ver1(wiki_data_body,'./body_index')\n",
        "  print(\"Building body index done. Building title index.\")\n",
        "  index_title=build_index_ver1(wiki_data_title,'./title_index')\n",
        "  print(\"Building title index done. Building anchor text index.\")\n",
        "  index_anchor=build_index_ver2(wiki_data_anchor,'./anchor_index')\n",
        "  print(\"Building anchor text index done. Indexing completed.\")"
      ],
      "metadata": {
        "id": "yhQtxuGhGC_A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#queries actions\n"
      ],
      "metadata": {
        "id": "rGliVCa-AVt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries=[q for q,d in queries_to_docs_raw.items()]\n",
        "q_tokenes_lst=[q.split() for q in queries]\n",
        "all_terms=[item for sublist in q_tokenes_lst for item in sublist]\n",
        "q_tokenes_dict={i:q for i,q in enumerate(q_tokenes_lst)}\n"
      ],
      "metadata": {
        "id": "JwMfvxFuUPPn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading big index and DLs : <font color='green'>Indexes here</font>"
      ],
      "metadata": {
        "id": "mpJvUecb_POD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading DLs"
      ],
      "metadata": {
        "id": "x51-BuxWK-9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading indexes"
      ],
      "metadata": {
        "id": "0dtBiZeVQBXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing posting locs to match local colab file location"
      ],
      "metadata": {
        "id": "b6xelcVSHza1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def change_index_locs(index):\n",
        "#     for term,loc_tuple in index.posting_locs.items():\n",
        "#       new_list = []\n",
        "#       for loc,offset in loc_tuple:\n",
        "#         splited = loc.split(\"/\")\n",
        "#         for part in splited:\n",
        "#           if \"index\" in part:\n",
        "#             rebuilt = part\n",
        "#           if \"bin\" in part:\n",
        "#             rebuilt = \"/content/drive/MyDrive/\" + rebuilt + \"/\" + part\n",
        "#         loc_tuple = (rebuilt,offset)\n",
        "#         new_list.append(loc_tuple)\n",
        "#       index.posting_locs[term] = new_list\n",
        "# if True: #Change to \"True\" to enable\n",
        "#   change_index_locs(body_index)\n",
        "#   change_index_locs(anchor_index)\n",
        "#   change_index_locs(title_index)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jhIDmsKwHyXD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # lst=list(title_index.posting_locs.values())[0]\n",
        "\n",
        "  # with closing(MultiFileReader()) as reader:\n",
        "  #   res=reader.read(lst, BLOCK_SIZE)\n",
        "  # res\n",
        "\n",
        "def find_postings(terms,index):\n",
        "    res={}\n",
        "    with closing(MultiFileReader()) as reader:\n",
        "        for w, locs in index.posting_locs.items():\n",
        "          if(res.keys()==terms):\n",
        "            break\n",
        "          if(w not in terms):\n",
        "            continue\n",
        "          else:\n",
        "            b = reader.read(locs, index.df[w] * TUPLE_SIZE)\n",
        "            posting_list = []\n",
        "            for i in range(index.df[w]):\n",
        "              doc_id = int.from_bytes(b[i*TUPLE_SIZE:i*TUPLE_SIZE+4], 'big')\n",
        "              tf = int.from_bytes(b[i*TUPLE_SIZE+4:(i+1)*TUPLE_SIZE], 'big')\n",
        "              posting_list.append((doc_id, tf))\n",
        "            res[w]=posting_list\n",
        "\n",
        "    return res\n",
        "            "
      ],
      "metadata": {
        "id": "6ZcqOr83jlLY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get top n with cosine simularity on the body index"
      ],
      "metadata": {
        "id": "6mWXTFEV_dd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rLlrnBimwmnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# works\n",
        "def generate_query_tfidf_vector(query_to_search,index,DL):\n",
        "    epsilon = .0000001\n",
        "    total_vocab_size = len(index.df.keys())\n",
        "    Q = np.zeros((total_vocab_size))\n",
        "    term_vector = list(index.df.keys())    \n",
        "    counter = Counter(query_to_search)\n",
        "    for token in np.unique(query_to_search):\n",
        "        if token.lower() in index.df.keys(): #avoid terms that do not appear in the index.               \n",
        "            tf = counter[token.lower()]/len(query_to_search) # term frequency divded by the length of the query\n",
        "            df = index.df[token.lower()]            \n",
        "            idf = math.log((len(DL))/(df+epsilon),10) #smoothing\n",
        "            \n",
        "            try:\n",
        "                ind = term_vector.index(token)\n",
        "                Q[ind] = tf*idf\n",
        "                     \n",
        "            except:\n",
        "                \n",
        "                pass\n",
        "    return Q\n",
        "\n",
        "# works\n",
        "def get_candidate_documents_and_scores(query_to_search,index,DL):\n",
        "    \"\"\"\n",
        "    Generate a dictionary representing a pool of candidate documents for a given query. This function will go through every token in query_to_search\n",
        "    and fetch the corresponding information (e.g., term frequency, document frequency, etc.') needed to calculate TF-IDF from the posting list.\n",
        "    Then it will populate the dictionary 'candidates.'\n",
        "    For calculation of IDF, use log with base 10.\n",
        "    tf will be normalized based on the length of the document.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    query_to_search: list of tokens (str). This list will be preprocessed in advance (e.g., lower case, filtering stopwords, etc.'). \n",
        "                     Example: 'Hello, I love information retrival' --->  ['hello','love','information','retrieval']\n",
        "\n",
        "    index:           inverted index loaded from the corresponding files.\n",
        "\n",
        "    words,pls: generator for working with posting.\n",
        "    Returns:\n",
        "    -----------\n",
        "    dictionary of candidates. In the following format:\n",
        "                                                               key: pair (doc_id,term)\n",
        "                                                               value: tfidf score. \n",
        "    \"\"\"\n",
        "    candidates = {}\n",
        "    N = len(DL)   \n",
        "    pls = find_postings(np.unique(query_to_search),index)\n",
        "\n",
        "    for term in np.unique(query_to_search): \n",
        "        if term.lower() in index.df.keys():            \n",
        "            list_of_doc = pls[term.lower()]                       \n",
        "            normlized_tfidf = [(doc_id,(freq/DL[str(doc_id)])*math.log(N/index.df[term.lower()],10)) for doc_id, freq in list_of_doc]           \n",
        "                        \n",
        "            for doc_id, tfidf in normlized_tfidf:\n",
        "                candidates[(doc_id,term.lower())] = candidates.get((doc_id,term.lower()), 0) + tfidf               \n",
        "     \n",
        "    return candidates\n",
        "\n",
        "# works\n",
        "def generate_document_tfidf_matrix(query_to_search,index,DL):\n",
        "    \"\"\"\n",
        "    Generate a DataFrame `D` of tfidf scores for a given query. \n",
        "    Rows will be the documents candidates for a given query\n",
        "    Columns will be the unique terms in the index.\n",
        "    The value for a given document and term will be its tfidf score.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    query_to_search: list of tokens (str). This list will be preprocessed in advance (e.g., lower case, filtering stopwords, etc.'). \n",
        "                     Example: 'Hello, I love information retrival' --->  ['hello','love','information','retrieval']\n",
        "\n",
        "    index:           inverted index loaded from the corresponding files.\n",
        "\n",
        "    words,pls: generator for working with posting.\n",
        "    Returns:\n",
        "    -----------\n",
        "    DataFrame of tfidf scores.\n",
        "    \"\"\"\n",
        "    \n",
        "    total_vocab_size = len(index.df)\n",
        "    candidates_scores = get_candidate_documents_and_scores(query_to_search,index,DL) #We do not need to utilize all document. Only the docuemnts which have corrspoinding terms with the query.\n",
        "    unique_candidates = np.unique([doc_id for doc_id, freq in candidates_scores.keys()])\n",
        "    \n",
        "    D = np.zeros((len(unique_candidates), total_vocab_size))\n",
        "    D = pd.DataFrame(D)\n",
        "    D.index = unique_candidates\n",
        "    D.columns = index.df.keys()\n",
        "\n",
        "    for key in candidates_scores:\n",
        "        tfidf = candidates_scores[key]\n",
        "        doc_id, term = key    \n",
        "        D.loc[doc_id][term] = tfidf\n",
        "\n",
        "    return D\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "def cosine_similarity(D,Q):\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity for each candidate document in D and a given query (e.g., Q).\n",
        "    Generate a dictionary of cosine similarity scores \n",
        "    key: doc_id\n",
        "    value: cosine similarity score\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    D: DataFrame of tfidf scores.\n",
        "\n",
        "    Q: vectorized query with tfidf scores\n",
        "    \n",
        "    Returns:\n",
        "    -----------\n",
        "    dictionary of cosine similarity score as follows:\n",
        "                                                                key: document id (e.g., doc_id)\n",
        "                                                                value: cosine similarty score.\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    # d ={}\n",
        "    # mat = D.to_numpy()\n",
        "   \n",
        "\n",
        "    # for i in range(0,len(mat)):\n",
        "    #   x1 = mat[i] / np.linalg.norm(mat[i])\n",
        "    #   x2 = Q / np.linalg.norm(Q)\n",
        "\n",
        "    #   val = np.matmul(x1, x2.T)\n",
        "    \n",
        "    #   d[i] = val\n",
        "\n",
        "\n",
        "    # return d\n",
        "    output = {}\n",
        "    for index, row in D.iterrows():\n",
        "      cos_sim = dot(row, Q)/(norm(row)*norm(Q))\n",
        "      \n",
        "      output[index] = cos_sim\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def get_top_n(sim_dict,N=3):\n",
        "    \"\"\" \n",
        "    Sort and return the highest N documents according to the cosine similarity score.\n",
        "    Generate a dictionary of cosine similarity scores \n",
        "   \n",
        "    Parameters:\n",
        "    -----------\n",
        "    sim_dict: a dictionary of similarity score as follows:\n",
        "                                                                key: document id (e.g., doc_id)\n",
        "                                                                value: similarity score. We keep up to 5 digits after the decimal point. (e.g., round(score,5))\n",
        "\n",
        "    N: Integer (how many documents to retrieve). By default N = 3\n",
        "    \n",
        "    Returns:\n",
        "    -----------\n",
        "    a ranked list of pairs (doc_id, score) in the length of N.\n",
        "    \"\"\"\n",
        "    \n",
        "    return sorted([(doc_id, builtins.round(score,5)) for doc_id, score in sim_dict.items()], key = lambda x: x[1],reverse=True)[:N]\n",
        "\n",
        "def get_topN_score_for_queries(queries_to_search,index,DL,N=3):\n",
        "    \"\"\" \n",
        "    Generate a dictionary that gathers for every query its topN score.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    queries_to_search: a dictionary of queries as follows: \n",
        "                                                        key: query_id\n",
        "                                                        value: list of tokens.\n",
        "    index:           inverted index loaded from the corresponding files.    \n",
        "    N: Integer. How many documents to retrieve. This argument is passed to the topN function. By default N = 3, for the topN function. \n",
        "    \n",
        "    Returns:\n",
        "    -----------\n",
        "    return: a dictionary of queries and topN pairs as follows:\n",
        "                                                        key: query_id\n",
        "                                                        value: list of pairs in the following format:(doc_id, score). \n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    d={}\n",
        "\n",
        "    for q_id,q_terms in queries_to_search.items():\n",
        "      Q=generate_query_tfidf_vector(q_terms,index,DL)\n",
        "      D=generate_document_tfidf_matrix(q_terms,index,DL)\n",
        "      cosim_dict=cosine_similarity(D,Q)\n",
        "\n",
        "        \n",
        "      d[q_id]=get_top_n(cosim_dict,N)\n",
        "\n",
        "    \n",
        "    return d\n"
      ],
      "metadata": {
        "id": "mVURFN9fPRF6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cosine_sim_result_body=get_topN_score_for_queries({i:[t.lower() for t in q_lst] for i,q_lst in q_tokenes_dict.items()},body_index,body_DL,N=99)\n",
        "#cosine_sim_result_anchor=get_topN_score_for_queries({i:[t.lower() for t in q_lst] for i,q_lst in q_tokenes_dict.items()},index_body,DL_anchor)\n"
      ],
      "metadata": {
        "id": "cwhEBGgVLwG8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3cf13a06-2805-465a-c90c-0ea12c917283"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f686729dd455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcosine_sim_result_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_topN_score_for_queries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq_lst\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_lst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq_tokenes_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody_DL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#cosine_sim_result_anchor=get_topN_score_for_queries({i:[t.lower() for t in q_lst] for i,q_lst in q_tokenes_dict.items()},index_body,DL_anchor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'body_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim_result_body"
      ],
      "metadata": {
        "id": "Xsu9Z5gOQ5-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# binary ranking using the title of articles and anchor text\n",
        "\n"
      ],
      "metadata": {
        "id": "-_yrc27ACNwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_ranking_for_anchor_text(query,index):\n",
        "  words,pls=zip(*index.posting_lists_iter())\n",
        "  matches = Counter()\n",
        "  for term in np.unique(query): \n",
        "        if term.lower() in words:            \n",
        "            list_of_doc = pls[words.index(term.lower())]    \n",
        "            for doc_id, freq in list_of_doc:\n",
        "                matches[doc_id] = matches.get(doc_id, 0) + 1\n",
        "  return sorted(matches.items(),key=lambda x:x[1], reverse =True)\n"
      ],
      "metadata": {
        "id": "d3mpgXUADtBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Anchor text ranking\n",
        "binary_ranking_for_anchor_text(q_tokenes_lst[0],index_title)"
      ],
      "metadata": {
        "id": "79b64OCWDt92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Title text ranking\n",
        "binary_ranking_for_anchor_text(q_tokenes_lst[1],anchor_index)"
      ],
      "metadata": {
        "id": "JU6jP_1gYkJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FFc_QYAHCJAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ranking by PageRank "
      ],
      "metadata": {
        "id": "oW8aTbO3DdNz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e884236d"
      },
      "outputs": [],
      "source": [
        "# Put your `generate_graph` function here\n",
        "def generate_graph(pages):\n",
        "  ''' Compute the directed graph generated by wiki links.\n",
        "  Parameters:\n",
        "  -----------\n",
        "    pages: RDD\n",
        "      An RDD where each row consists of one wikipedia articles with 'id' and \n",
        "      'anchor_text'.\n",
        "  Returns:\n",
        "  --------\n",
        "    edges: RDD\n",
        "      An RDD where each row represents an edge in the directed graph created by\n",
        "      the wikipedia links. The first entry should the source page id and the \n",
        "      second entry is the destination page id. No duplicates should be present. \n",
        "    vertices: RDD\n",
        "      An RDD where each row represents a vetrix (node) in the directed graph \n",
        "      created by the wikipedia links. No duplicates should be present. \n",
        "  '''\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "  temp = pages.partitionBy(16) #partitioning for speed\n",
        "  sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
        "  edges = temp.flatMap(lambda x:[(x[0],each[0]) for each in x[1]]).distinct() ## might have dupli\n",
        "  p1 = temp.flatMap(lambda x:[(each[0],) for each in x[1]])\n",
        "  p2 = temp.map(lambda x:(x[0],))\n",
        "  vert = p1.union(p2).distinct()\n",
        "  return edges,vert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5edcc5a0",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-PageRank",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "t_start = time()\n",
        "#pages_links = spark.read.parquet(\"gs://wikidata_preprocessed/*\").select(\"id\", \"anchor_text\").rdd\n",
        "# construct the graph \n",
        "edges, vertices = generate_graph(wiki_data_anchor)\n",
        "# compute PageRank\n",
        "edgesDF = edges.toDF(['src', 'dst']).repartition(124, 'src')\n",
        "verticesDF = vertices.toDF(['id']).repartition(124, 'id')\n",
        "g = GraphFrame(verticesDF, edgesDF)\n",
        "pr_results = g.pageRank(resetProbability=0.15, maxIter=6)\n",
        "pr = pr_results.vertices.select(\"id\", \"pagerank\")\n",
        "pr = pr.sort(col('pagerank').desc())\n",
        "#pr.repartition(1).write.csv(f'gs://{bucket_name}/pr', compression=\"gzip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pr"
      ],
      "metadata": {
        "id": "7Qn2ZO6eSN07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ranking by article page views "
      ],
      "metadata": {
        "id": "0H9HtYRnD1l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "# Using user page views (as opposed to spiders and automated traffic) for the \n",
        "# month of August 2021\n",
        "pv_path = 'https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2'\n",
        "p = Path(pv_path) \n",
        "pv_name = p.name\n",
        "pv_temp = f'{p.stem}-4dedup.txt'\n",
        "pv_clean = f'{p.stem}.pkl'\n",
        "# Download the file (2.3GB) \n",
        "!wget -N $pv_path\n",
        "# Filter for English pages, and keep just two fields: article ID (3) and monthly \n",
        "# total number of page views (5). Then, remove lines with article id or page \n",
        "# view values that are not a sequence of digits.\n",
        "!bzcat $pv_name | grep \"^en\\.wikipedia\" | cut -d' ' -f3,5 | grep -P \"^\\d+\\s\\d+$\" > $pv_temp\n",
        "# Create a Counter (dictionary) that sums up the pages views for the same \n",
        "# article, resulting in a mapping from article id to total page views.\n",
        "wid2pv = Counter()\n",
        "with open(pv_temp, 'rt') as f:\n",
        "  for line in f:\n",
        "    parts = line.split(' ')\n",
        "    wid2pv.update({int(parts[0]): int(parts[1])})\n",
        "# write out the counter as binary file (pickle it)\n",
        "with open(pv_clean, 'wb') as f:\n",
        "  pickle.dump(wid2pv, f)\n",
        "# read in the counter\n",
        "with open(pv_clean, 'rb') as f:\n",
        "  wid2pv = pickle.loads(f.read())"
      ],
      "metadata": {
        "id": "S-bCvdFNimGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#getting top n with bm25 "
      ],
      "metadata": {
        "id": "opkGx9riBykd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQKCt86l3_ml"
      },
      "outputs": [],
      "source": [
        "def get_candidate_documents(query_to_search,index,words,pls):\n",
        "    \"\"\"\n",
        "    Generate a dictionary representing a pool of candidate documents for a given query. \n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    query_to_search: list of tokens (str). This list will be preprocessed in advance (e.g., lower case, filtering stopwords, etc.'). \n",
        "                     Example: 'Hello, I love information retrival' --->  ['hello','love','information','retrieval']\n",
        "\n",
        "    index:           inverted index loaded from the corresponding files.\n",
        "\n",
        "    words,pls: generator for working with posting.\n",
        "    Returns:\n",
        "    -----------\n",
        "    list of candidates. In the following format:\n",
        "                                                               key: pair (doc_id,term)\n",
        "                                                               value: tfidf score. \n",
        "    \"\"\"\n",
        "    candidates = []    \n",
        "    for term in np.unique(query_to_search):\n",
        "        if term in words:        \n",
        "            current_list = (pls[words.index(term)])               \n",
        "            candidates += current_list  \n",
        "\n",
        "    return np.unique([d for d,s in candidates])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "nPOS5HoohGTJ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1866e668d1c0d235e49d047c4ff954ad",
          "grade": false,
          "grade_id": "cell-bb4b866e29cf18ab",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from itertools import chain\n",
        "import time\n",
        "# When preprocessing the data have a dictionary of document length for each document saved in a variable called `DL`.\n",
        "class BM25_from_index:\n",
        "    \"\"\"\n",
        "    Best Match 25.    \n",
        "    ----------\n",
        "    k1 : float, default 1.5\n",
        "\n",
        "    b : float, default 0.75\n",
        "\n",
        "    index: inverted index\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,index,k1=1.5, b=0.75):\n",
        "        self.b = b\n",
        "        self.k1 = k1\n",
        "        self.index = index\n",
        "        self.N = len(DL)\n",
        "        self.AVGDL = builtins.sum(DL.values())/self.N\n",
        "        self.words, self.pls = zip(*self.index.posting_lists_iter())        \n",
        "\n",
        "    def calc_idf(self,list_of_tokens):\n",
        "        \"\"\"\n",
        "        This function calculate the idf values according to the BM25 idf formula for each term in the query.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
        "        \n",
        "        Returns:\n",
        "        -----------\n",
        "        idf: dictionary of idf scores. As follows: \n",
        "                                                    key: term\n",
        "                                                    value: bm25 idf score\n",
        "        \"\"\"        \n",
        "        idf = {}        \n",
        "        for term in list_of_tokens:            \n",
        "            if term in self.index.df.keys():\n",
        "                n_ti = self.index.df[term]\n",
        "                idf[term] = math.log(1 + (self.N - n_ti + 0.5) / (n_ti + 0.5))\n",
        "            else:\n",
        "                pass                             \n",
        "        return idf\n",
        "        \n",
        "\n",
        "    def search(self, queries,N=3):\n",
        "        \"\"\"\n",
        "        This function calculate the bm25 score for given query and document.\n",
        "        We need to check only documents which are 'candidates' for a given query. \n",
        "        This function return a dictionary of scores as the following:\n",
        "                                                                    key: query_id\n",
        "                                                                    value: a ranked list of pairs (doc_id, score) in the length of N.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
        "        doc_id: integer, document id.\n",
        "        \n",
        "        Returns:\n",
        "        -----------\n",
        "        score: float, bm25 score.\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        terms = []\n",
        "        for query in queries:\n",
        "          for term in query:\n",
        "            terms.append(term)\n",
        "        uniques = set(terms)\n",
        "        self.idf = self.calc_idf(uniques)\n",
        "\n",
        "        output = OrderedDict()\n",
        "        for i,query in enumerate(queries):\n",
        "            scores = []\n",
        "            candidates = get_candidate_documents(query,self.index,self.words,self.pls)\n",
        "\n",
        "\n",
        "            scores.append([(doc_id,builtins.round(self._score(query, doc_id),3)) for doc_id in (([i for i in candidates]))])\n",
        "            scores = scores[0]\n",
        "            scores.sort(reverse = True,key = lambda x:x[1])\n",
        "            # output[' '.join(query)] = scores[:N]\n",
        "            output[i] = scores[:N]\n",
        "        return output\n",
        "\n",
        "    def _score(self, query, doc_id):\n",
        "        \"\"\"\n",
        "        This function calculate the bm25 score for given query and document.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
        "        doc_id: integer, document id.\n",
        "        \n",
        "        Returns:\n",
        "        -----------\n",
        "        score: float, bm25 score.\n",
        "        \"\"\"        \n",
        "        score = 0.0        \n",
        "        doc_len = DL[doc_id]        \n",
        "             \n",
        "        for term in query:\n",
        "            if term in self.index.df.keys():                \n",
        "                term_frequencies = dict(self.pls[self.words.index(term)])                \n",
        "                if doc_id in term_frequencies.keys():            \n",
        "                    freq = term_frequencies[doc_id]\n",
        "                    numerator = self.idf[term] * freq * (self.k1 + 1)\n",
        "                    denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.AVGDL)\n",
        "                    score += (numerator / denominator)\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tQ7pM7oGyAe"
      },
      "outputs": [],
      "source": [
        "bm25_body = BM25_from_index(index_body)\n",
        "# for lst in bm25_title.pls:\n",
        "#   if 1 in lst:\n",
        "#     print(lst)\n",
        "quety_terms_lst=[q.lower().split() for q,docs in queries_to_docs_raw.items()]\n",
        "query2doc_bm25=bm25_body.search(quety_terms_lst,N=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimate\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bd__I0S85M5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "def intersection(l1,l2):      \n",
        "    \"\"\"\n",
        "    This function perform an intersection between two lists.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    l1: list of documents. Each element is a doc_id.\n",
        "    l2: list of documents. Each element is a doc_id.\n",
        "\n",
        "    Returns:\n",
        "    ----------\n",
        "    list with the intersection (without duplicates) of l1 and l2\n",
        "    \"\"\"\n",
        "    return list(builtins.set(l1)&builtins.set(l2))\n",
        "def precision_at_k(true_list,predicted_list,k=40):    \n",
        "    \"\"\"\n",
        "    This function calculate the precision@k metric.\n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "    true_list: list of relevant documents. Each element is a doc_id.\n",
        "    predicted_list: sorted list of documents predicted as relevant. Each element is a doc_id. Sorted is performed by relevance score\n",
        "    k: integer, a number to slice the length of the predicted_list\n",
        "    \n",
        "    Returns:\n",
        "    -----------\n",
        "    float, precision@k with 3 digits after the decimal point.\n",
        "    \"\"\"      \n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    up=len(intersection(predicted_list[:k],true_list))\n",
        "    down=k\n",
        "    return builtins.round(up/down,3)\n",
        "\n",
        "def average_precision(true_list,predicted_list,k=40):\n",
        "    \"\"\"\n",
        "    This function calculate the average_precision@k metric.(i.e., precision in every recall point).     \n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "    true_list: list of relevant documents. Each element is a doc_id.\n",
        "    predicted_list: sorted list of documents predicted as relevant. Each element is a doc_id. Sorted is performed by relevance score\n",
        "    k: integer, a number to slice the length of the predicted_list\n",
        "    \n",
        "    Returns:\n",
        "    -----------\n",
        "    float, average precision@k with 3 digits after the decimal point.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    # for each relevant doc that in pl and in tl activate p@k and sum them,after \n",
        "    #devide by number of relevant\n",
        "    sum=0\n",
        "    rel=len(intersection(predicted_list[:k],true_list))\n",
        "    if rel==0:\n",
        "      return 0\n",
        "    for i_pl,doc in enumerate(predicted_list[:k]):\n",
        "      if doc in true_list:\n",
        "        sum+=precision_at_k(true_list,predicted_list[:k],i_pl+1)\n",
        "    return builtins.round(sum/rel,3)\n",
        "\n",
        "def mean_ap(true_dict,predicted_dict,k=40):\n",
        "  sum=0\n",
        "  for q_id,true_lst in true_dict.items():\n",
        "    sum+=average_precision(true_lst,predicted_dict[q_id])\n",
        "  return sum/len(true_dict)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "RxpG4Yhgub-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qid_to_true_docs_dict={i:d[1] for i,d in enumerate(queries_to_docs_raw.items())}\n",
        "d=get_topN_score_for_queries({i:[t.lower() for t in q_lst] for i,q_lst in q_tokenes_dict.items()},index_body,40)\n",
        "qid_to_returned_docs_dict={i:t[0] for i,t in d.items()}\n",
        "map_cosim_body=mean_ap(qid_to_true_docs_dict,qid_to_returned_docs_dict)\n",
        "\n",
        "\n",
        "bm25_dict={qid:[doc for doc,s in lst] for qid,lst in query2doc_bm25.items()}\n",
        "map_bm25_body=mean_ap(qid_to_true_docs_dict,bm25_dict,40)\n",
        "# average_precision(q_tokenes_dict[0],cosine_sim_result[0])"
      ],
      "metadata": {
        "id": "H6A6a4yx6vgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('cosine simularity strategy MAP@40 score: '+str(map_cosim_body))\n",
        "print('bm25 strategy MAP@40 score: '+str(map_bm25_body))"
      ],
      "metadata": {
        "id": "i_UVlQIa05BW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}